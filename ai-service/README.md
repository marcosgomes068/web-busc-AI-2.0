# Configura√ß√£o do Microservi√ßo AI

Esta √© uma solu√ß√£o robusta que separa a funcionalidade de IA em um microservi√ßo Python Flask, resolvendo os problemas de compatibilidade com a API do Cohere.

## Arquitetura

```
BUSC-AI 2.0 (Node.js)
    ‚Üì HTTP Requests
AI Microservice (Python Flask)
    ‚Üì API Calls
Cohere API
```

## Instala√ß√£o e Configura√ß√£o

### 1. Configurar o Microservi√ßo AI (Python)

```bash
# Navegar para o diret√≥rio do microservi√ßo
cd ai-service

# Executar o script de configura√ß√£o (Windows)
setup.bat

# Ou para Linux/Mac
chmod +x setup.sh
./setup.sh
```

### 2. Configurar as Chaves de API

Edite o arquivo `ai-service\.env`:
```env
COHERE_API_KEY=sua_chave_cohere_aqui
PORT=5000
FLASK_ENV=development
```

### 3. Iniciar o Microservi√ßo

```bash
cd ai-service
python app.py
```

O servi√ßo estar√° dispon√≠vel em `http://localhost:5000`

### 4. Testar o Sistema Principal

```bash
# No diret√≥rio principal
npm start
```

## Vantagens desta Arquitetura

### üöÄ **Robustez**
- **Fallbacks Autom√°ticos**: Se o microservi√ßo estiver indispon√≠vel, usa an√°lise local
- **Health Checks**: Verifica automaticamente se o servi√ßo est√° funcionando
- **Timeouts**: Evita travamentos do sistema principal

### üîß **Flexibilidade**
- **Troca de Providers**: F√°cil altera√ß√£o entre Cohere, OpenAI, ou Ollama
- **Configura√ß√£o Independente**: O microservi√ßo tem suas pr√≥prias depend√™ncias
- **Escalabilidade**: Pode ser executado em containers separados

### üí∞ **Economia**
- **Cache Inteligente**: Evita chamadas desnecess√°rias √† API
- **Rate Limiting**: Controla o uso da API
- **Modo Fallback**: Funciona mesmo sem cr√©ditos de API

### üêõ **Debugging**
- **Logs Separados**: Facilita identificar problemas
- **Endpoints de Health**: Monitora o status do servi√ßo
- **Versionamento Independente**: Atualiza√ß√µes sem afetar o sistema principal

## Endpoints Dispon√≠veis

### `GET /health`
Verifica se o microservi√ßo est√° funcionando:
```json
{
  "status": "healthy",
  "cohere_available": true,
  "timestamp": "2025-08-03T19:45:00.000Z"
}
```

### `POST /analyze-query`
Analisa uma consulta de pesquisa:
```json
{
  "query": "Como fazer um bolo de chocolate?"
}
```

### `POST /generate-keywords`
Gera palavras-chave para um t√≥pico:
```json
{
  "topic": "intelig√™ncia artificial"
}
```

## Pr√≥ximos Passos

### Op√ß√£o 1: Usar o Microservi√ßo Flask
1. Configure a chave do Cohere no `ai-service\.env`
2. Execute `cd ai-service && python app.py`
3. Execute `npm start` no diret√≥rio principal

### Op√ß√£o 2: Migrar para OpenAI (alternativa)
Se preferir usar OpenAI em vez de Cohere, posso adaptar o c√≥digo.

### Op√ß√£o 3: Implementar Ollama Local
Para uma solu√ß√£o completamente gratuita e offline.

## Status Atual

‚úÖ **Funcionando**: Sistema principal em Node.js
‚úÖ **Funcionando**: Microservi√ßo Flask com fallbacks
‚ö†Ô∏è **Pendente**: Configura√ß√£o da chave Cohere v√°lida
üîÑ **Em desenvolvimento**: Endpoints completos de summariza√ß√£o

Qual op√ß√£o voc√™ gostaria de seguir?
